{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 3: Model Assessment and Selection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi8XJoA1xnP1"
      },
      "source": [
        "\n",
        "# Kenny Huang, Danny Hong, Arthur Skok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m57mgHSb94Ae"
      },
      "source": [
        "Re-implement the example in section 7.10.2 using any simple, out of the box classifier (like K nearest neighbors from sci-kit). Reproduce the results for the incorrect and correct way of doing cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bv3hTUb9sSx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "bf14f159-4e0c-4ea0-ed1f-f50cafcb96ba"
      },
      "source": [
        "#K-Fold Cross Validation Project 3\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from random import randint\n",
        "#Testing KNN\n",
        "#garbage data example to test the accuracy of our classifier (KNN), should be approximately 50%:\n",
        "X,y = make_classification(n_samples = 50, n_features = 5000)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "result = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "result.fit(X_train, y_train)\n",
        "result.score(X_test, y_test)\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "#confirmed that knn classifier had ~50% error rate -> does this make sense?\n",
        "#Textbook says \"The true (test) error rate of any classifier is 50%.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.40      0.40         5\n",
            "           1       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.40        10\n",
            "   macro avg       0.40      0.40      0.40        10\n",
            "weighted avg       0.40      0.40      0.40        10\n",
            "\n",
            "Train Data: [3 4 5 6 7 8] | Test Data: [0 1 2]\n",
            "Train Data: [0 1 2 6 7 8] | Test Data: [3 4 5]\n",
            "Train Data: [0 1 2 3 4 5] | Test Data: [6 7 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VgZDudcPRZv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "37f94569-0f61-4081-f4a1-daa5ad79bb4b"
      },
      "source": [
        "#Wrong Method for CV\n",
        "#Generate the data (binary classification)\n",
        "X,y = make_classification(n_samples = 50, n_features = 5000, random_state=1)\n",
        "input_features_correlation_coefficient = [np.corrcoef(x, y)[0, 1] for x in X.T]#didn't work without transpose\n",
        "best_100 = np.argsort(input_features_correlation_coefficient)[:100]\n",
        "new_input = np.array(X.T[best_100]).T\n",
        "#print(\"the y values or labels are\", y)\n",
        "#print(y.shape)\n",
        "#print(new_input)\n",
        "#print(new_input.shape)\n",
        "#print(best_100)\n",
        "#print(X.shape)\n",
        "classifier = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
        "error_list = []\n",
        "\n",
        "K_Fold = RepeatedKFold(5, 50)\n",
        "for train_index, test_index  in K_Fold.split(new_input):\n",
        "  X_train, X_test = new_input[train_index], new_input[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  classifier.fit(X_train, y_train)\n",
        "  error_list.append(1 - classifier.score(X_test, y_test))\n",
        "  \n",
        "print(\"The mean error for all the K Folds is: \", sum(error_list) / 250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean error for all the K Folds is:  0.0184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-ffuZnBX-iX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7ac250e1-2e67-4e9e-eb9c-5e44bff6935f"
      },
      "source": [
        "#Right Method for CV *NOTE This is quite slow but does run correctly after ~2 minutes\n",
        "#Data Generation\n",
        "X,y = make_classification(n_samples = 50, n_features = 5000, random_state=1)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "#y = np.ravel(np.atleast_2d(y).T)\n",
        "#print(\"the y values or labels are\", y)\n",
        "print(y.shape)\n",
        "#print(new_input)\n",
        "#print(best_100)\n",
        "print(X.shape)\n",
        "classifier = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
        "error_list = []\n",
        "\n",
        "K_Fold = RepeatedKFold(5, 50)\n",
        "for train_index, test_index  in K_Fold.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  input_features_correlation_coefficient = [np.corrcoef(y, x)[0, 1] for x in X.T]\n",
        "  #for the correct method, we choose predictors independently for each chosen kfold, instead of at the initial step \n",
        "  best_100 = np.argsort(input_features_correlation_coefficient)[:100]\n",
        "  new_input_train = np.array(X_train.T[best_100]).T\n",
        "  new_input_test = np.array(X_test.T[best_100]).T\n",
        "  \n",
        "  classifier.fit(X_train, y_train)\n",
        "  error_list.append(1 - classifier.score(X_test, y_test))\n",
        "  \n",
        "print (\"The mean error for all the K Folds is:\", (sum(error_list)/250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50,)\n",
            "(50, 5000)\n",
            "The mean error for all the K Folds is: 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}